{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:46:11.165276700Z",
     "start_time": "2023-08-30T17:46:04.714794400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 1.13.1+cpu\n",
      "main3_mlp_central\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__}\")\n",
    "print('main3_mlp_central')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:46:11.265010100Z",
     "start_time": "2023-08-30T17:46:11.139346100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = torch.load('./dataset3/X.pt')\n",
    "y = torch.load('./dataset3/y.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:46:11.370451600Z",
     "start_time": "2023-08-30T17:46:11.188215500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train(net, optimizer, x, y, x_test, y_test, num_epoch=64, batch_size=128):\n",
    "  print_every = -1\n",
    "  test_loss = []\n",
    "\n",
    "  for n in range(num_epoch):\n",
    "    # Mini batch sgd\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "    for i in range(0, x.size()[0], batch_size):\n",
    "      indices = permutation[i:i+batch_size]\n",
    "      x_mini, y_mini = x[indices], y[indices]\n",
    "      y_pred = net(x_mini)\n",
    "\n",
    "      loss = nn.MSELoss()(y_pred, y_mini)\n",
    "      optimizer.zero_grad()\n",
    "      loss.mean().backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  return test_loss\n",
    "\n",
    "\n",
    "def test(net, x_test, y_test):\n",
    "  with torch.no_grad():\n",
    "    y_pred = net(x_test)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_test = y_test.detach().numpy()\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    #print('auc', auc)\n",
    "    return mse, auc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:48:12.067628100Z",
     "start_time": "2023-08-30T17:48:11.918027800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Local model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "random_state = np.random.randint(1000)\n",
    "def fl_split(split, x_train, y_train):\n",
    "\n",
    "    x_eq = []\n",
    "    y_eq = []\n",
    "\n",
    "    n_splits = 50\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "    for i, (_, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "        x_eq.append(x_train[test_index])\n",
    "        y_eq.append(y_train[test_index])\n",
    "\n",
    "    x_split = []\n",
    "    y_split = []\n",
    "\n",
    "    acc = 0\n",
    "    for s in split:\n",
    "        x_split.append(torch.cat(x_eq[acc:acc+int(s*n_splits)], 0))\n",
    "        y_split.append(torch.cat(y_eq[acc:acc+int(s*n_splits)], 0))\n",
    "        acc += int(s*n_splits)\n",
    "\n",
    "    return x_split, y_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:48:14.957069600Z",
     "start_time": "2023-08-30T17:48:14.443032100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from net_archs import MLP\n",
    "import datetime\n",
    "\n",
    "def run_local(split, X=X, y=y):\n",
    "    mses = []\n",
    "    aucs = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "        print(f\"Fold {fold_idx + 1}:\")\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        x_split, y_split = fl_split(split, X_train, y_train)\n",
    "\n",
    "        for X_train, y_train in zip(x_split, y_split):\n",
    "            ros = RandomOverSampler(random_state=random_state)\n",
    "            X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "            X_train = torch.from_numpy(X_train)\n",
    "\n",
    "            y_train = torch.reshape(torch.from_numpy(y_train), (-1, 1))\n",
    "            y_test = torch.reshape(y_test, (-1, 1))\n",
    "\n",
    "            model = MLP(10, 1, layer_size=64, num_of_layers=2)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.00001)\n",
    "            train(model, optimizer, X_train, y_train, X_test, y_test, num_epoch=10, batch_size=32)\n",
    "            mse, auc = test(model, X_test, y_test)\n",
    "\n",
    "            aucs.append(auc)\n",
    "            mses.append(mse)\n",
    "    end = datetime.datetime.now()\n",
    "    time = end - start\n",
    "\n",
    "    print('split',split)\n",
    "    print('Training time: ', time)\n",
    "    print('mse',mses)\n",
    "    print('auc',aucs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:49:11.230312900Z",
     "start_time": "2023-08-30T17:49:11.094677700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m split \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m----> 2\u001B[0m \u001B[43mrun_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 32\u001B[0m, in \u001B[0;36mrun_local\u001B[1;34m(split, X, y)\u001B[0m\n\u001B[0;32m     30\u001B[0m model \u001B[38;5;241m=\u001B[39m MLP(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m, layer_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, num_of_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     31\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00005\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[1;32m---> 32\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m mse, auc \u001B[38;5;241m=\u001B[39m test(model, X_test, y_test)\n\u001B[0;32m     35\u001B[0m aucs\u001B[38;5;241m.\u001B[39mappend(auc)\n",
      "Cell \u001B[1;32mIn[5], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, optimizer, x, y, x_test, y_test, num_epoch, batch_size)\u001B[0m\n\u001B[0;32m     13\u001B[0m   loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()(y_pred, y_mini)\n\u001B[0;32m     14\u001B[0m   optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 15\u001B[0m   \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m   optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#   if print_every != -1 and (i / batch_size) % print_every == 0:\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#     print(f'Epoch: {n + 1}, Iteration: {round(i / batch_size)}, Loss: {loss.sum()}')\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# if print_every == -1:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#test_loss.append(mse)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#print(f'Epoch {n} auc {auc}')\u001B[39;00m\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    487\u001B[0m     )\n\u001B[1;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "split = [1]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:49:26.361657100Z",
     "start_time": "2023-08-30T17:49:13.509397400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "torch.Size([60000, 10])\n",
      "auc 0.8120392322062427\n",
      "auc 0.8120392322062427\n",
      "torch.Size([60000, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m split \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m]\n\u001B[1;32m----> 2\u001B[0m \u001B[43mrun_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 29\u001B[0m, in \u001B[0;36mrun_local\u001B[1;34m(split)\u001B[0m\n\u001B[0;32m     27\u001B[0m model \u001B[38;5;241m=\u001B[39m MLP(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m, layer_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, num_of_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     28\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00005\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[1;32m---> 29\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m mse, auc \u001B[38;5;241m=\u001B[39m test(model, X_test, y_test)\n\u001B[0;32m     32\u001B[0m aucs\u001B[38;5;241m.\u001B[39mappend(auc)\n",
      "Cell \u001B[1;32mIn[3], line 16\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, optimizer, x, y, x_test, y_test, num_epoch, batch_size)\u001B[0m\n\u001B[0;32m     14\u001B[0m   optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     15\u001B[0m   loss\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 16\u001B[0m   \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#   if print_every != -1 and (i / batch_size) % print_every == 0:\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#     print(f'Epoch: {n + 1}, Iteration: {round(i / batch_size)}, Loss: {loss.sum()}')\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# if print_every == -1:\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#   print(f'Epoch: {n + 1}, Loss: {loss.sum()}')\u001B[39;00m\n\u001B[0;32m     23\u001B[0m mse, auc \u001B[38;5;241m=\u001B[39m test(net, x_test, y_test)\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m--> 140\u001B[0m     out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 23\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\optim\\adam.py:234\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure, grad_scaler)\u001B[0m\n\u001B[0;32m    231\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    232\u001B[0m             state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m--> 234\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m         \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m         \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m         \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m         \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m         \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[43m         \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    247\u001B[0m \u001B[43m         \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    248\u001B[0m \u001B[43m         \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    249\u001B[0m \u001B[43m         \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    250\u001B[0m \u001B[43m         \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[43m         \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m         \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\optim\\adam.py:300\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    298\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 300\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    303\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    304\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\optim\\adam.py:354\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    351\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 354\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[43mgrad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(param):\n\u001B[0;32m    357\u001B[0m     grad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mview_as_real(grad)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "split = [0.5, 0.5]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T20:49:48.907699400Z",
     "start_time": "2023-08-27T20:49:31.502287Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split = [0.6, 0.4]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "torch.Size([12000, 10])\n",
      "auc 0.7007957910515759\n",
      "auc 0.7580617013615889\n",
      "auc 0.7830541696364932\n",
      "auc 0.7939972150987208\n",
      "auc 0.7994540417808672\n",
      "auc 0.7996855045521012\n",
      "auc 0.8011624574733084\n",
      "auc 0.8018834823757631\n",
      "auc 0.8018540902778287\n",
      "auc 0.8023464079182312\n",
      "auc 0.8015767023535723\n",
      "auc 0.8017861210513554\n",
      "auc 0.8015197551638241\n",
      "auc 0.8009521202724648\n",
      "auc 0.8011946050804242\n",
      "auc 0.8011946050804242\n",
      "torch.Size([108000, 10])\n",
      "auc 0.8301970729117798\n",
      "auc 0.8342739710538193\n",
      "auc 0.8357062463107455\n",
      "auc 0.8366664307180619\n",
      "auc 0.8359890448529382\n",
      "auc 0.8356839740485179\n",
      "auc 0.8374738002238143\n",
      "auc 0.8370032329197014\n",
      "auc 0.837902442624866\n",
      "auc 0.8379007546679845\n",
      "auc 0.8380593458895257\n",
      "auc 0.8375183776305466\n",
      "auc 0.8377611803632568\n",
      "auc 0.837226229560952\n",
      "auc 0.8378465975579124\n",
      "auc 0.8378465975579124\n",
      "[0.1, 0.9]\n",
      "[0.8011946050804242, 0.8378465975579124]\n",
      "client mse [0.15911835 0.14056116]\n",
      "client auc [0.80119461 0.8378466 ]\n"
     ]
    }
   ],
   "source": [
    "split = [0.8, 0.2]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T22:13:51.636011Z",
     "start_time": "2023-08-27T22:06:06.935964800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split = [0.34, 0.33, 0.33]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "[0.6, 0.2, 0.2]\n",
      "[0.8336498340372493, 0.8250584821428572, 0.8171984375]\n",
      "client mse [0.14485916 0.15435468 0.1622122 ]\n",
      "client auc [0.83364983 0.82505848 0.81719844]\n"
     ]
    }
   ],
   "source": [
    "split = [0.6, 0.2, 0.2]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T23:24:18.927512400Z",
     "start_time": "2023-08-27T23:20:46.683921700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "[0.8, 0.1, 0.1]\n",
      "[0.8389191512624855, 0.7945321428571429, 0.8101535714285715]\n",
      "client mse [0.15591994 0.18518001 0.15593214]\n",
      "client auc [0.83891915 0.79453214 0.81015357]\n"
     ]
    }
   ],
   "source": [
    "split = [0.8, 0.1, 0.1]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T23:20:46.679932500Z",
     "start_time": "2023-08-27T23:17:02.831111400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "[0.6, 0.1, 0.1, 0.1, 0.1]\n",
      "[0.8328602787581267, 0.8208732142857144, 0.8035857142857143, 0.7924803571428571, 0.8064232142857144]\n",
      "client mse [0.14502504 0.16205046 0.18040295 0.17702585 0.15839897]\n",
      "client auc [0.83286028 0.82087321 0.80358571 0.79248036 0.80642321]\n"
     ]
    }
   ],
   "source": [
    "split = [0.6, 0.1, 0.1, 0.1, 0.1]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T01:14:26.573491900Z",
     "start_time": "2023-08-28T01:10:53.405236200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "[0.8, 0.05, 0.05, 0.05, 0.05]\n",
      "[0.8398367737569369, 0.8553962053571429, 0.8191517857142857, 0.8169140625, 0.7640457589285714]\n",
      "client mse [0.14810213 0.16924135 0.16573179 0.16033974 0.14372839]\n",
      "client auc [0.83983677 0.85539621 0.81915179 0.81691406 0.76404576]\n"
     ]
    }
   ],
   "source": [
    "split = [0.8, 0.05, 0.05, 0.05, 0.05]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T01:10:53.406233300Z",
     "start_time": "2023-08-28T01:07:24.423764100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m split \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m,\n\u001B[0;32m      2\u001B[0m         \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m]\n\u001B[1;32m----> 3\u001B[0m \u001B[43mrun_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 32\u001B[0m, in \u001B[0;36mrun_local\u001B[1;34m(split, X, y)\u001B[0m\n\u001B[0;32m     30\u001B[0m model \u001B[38;5;241m=\u001B[39m MLP(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m, layer_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, num_of_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     31\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00005\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[1;32m---> 32\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m mse, auc \u001B[38;5;241m=\u001B[39m test(model, X_test, y_test)\n\u001B[0;32m     35\u001B[0m aucs\u001B[38;5;241m.\u001B[39mappend(auc)\n",
      "Cell \u001B[1;32mIn[5], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, optimizer, x, y, x_test, y_test, num_epoch, batch_size)\u001B[0m\n\u001B[0;32m     13\u001B[0m   loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()(y_pred, y_mini)\n\u001B[0;32m     14\u001B[0m   optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 15\u001B[0m   \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m   optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#   if print_every != -1 and (i / batch_size) % print_every == 0:\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#     print(f'Epoch: {n + 1}, Iteration: {round(i / batch_size)}, Loss: {loss.sum()}')\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# if print_every == -1:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#test_loss.append(mse)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#print(f'Epoch {n} auc {auc}')\u001B[39;00m\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    487\u001B[0m     )\n\u001B[1;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\FD\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "split = [0.1, 0.1, 0.1, 0.1, 0.1,\n",
    "        0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:51:17.764159200Z",
     "start_time": "2023-08-30T17:49:36.068256500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "torch.Size([48000, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "torch.Size([7200, 10])\n",
      "[0.4, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.06, 0.06, 0.06]\n",
      "[0.8374646617750832, 0.8068901697685065, 0.8109559507577808, 0.7961929563492064, 0.8180406746031745, 0.8311259920634921, 0.8289434523809525, 0.7926860119047618, 0.8125049603174602, 0.823874007936508]\n",
      "client mse [0.14670356 0.17391726 0.16069983 0.15369567 0.16048577 0.15651706\n",
      " 0.16144638 0.15831232 0.15309429 0.1551771 ]\n",
      "client auc [0.83746466 0.80689017 0.81095595 0.79619296 0.81804067 0.83112599\n",
      " 0.82894345 0.79268601 0.81250496 0.82387401]\n"
     ]
    }
   ],
   "source": [
    "split = [0.4, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.06, 0.06, 0.06]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T23:06:01.490311100Z",
     "start_time": "2023-08-27T23:03:00.623229200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "[0.6, 0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04, 0.04]\n",
      "[0.8328513351755795, 0.7889843750000001, 0.7977455357142856, 0.7480468750000001, 0.7957756696428571, 0.8151897321428572, 0.8558872767857143, 0.8404575892857142, 0.8214787946428571, 0.7500613839285714]\n",
      "client mse [0.14797236 0.16713153 0.15241122 0.18521674 0.17096385 0.17195275\n",
      " 0.17783752 0.1654726  0.16510616 0.14491653]\n",
      "client auc [0.83285134 0.78898438 0.79774554 0.74804688 0.79577567 0.81518973\n",
      " 0.85588728 0.84045759 0.82147879 0.75006138]\n"
     ]
    }
   ],
   "source": [
    "split = [0.6, 0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04, 0.04]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T01:21:57.430057100Z",
     "start_time": "2023-08-28T01:18:13.796945500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "[0.8, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]\n",
      "[0.8369004819305601, 0.7663392857142858, 0.7092410714285714, 0.7622321428571429, 0.8107142857142857, 0.73390625, 0.7917410714285715, 0.7628571428571429, 0.8219642857142857, 0.7046428571428571]\n",
      "client mse [0.15644191 0.18714832 0.19965808 0.20672046 0.18479377 0.19478165\n",
      " 0.17306052 0.19586898 0.18460417 0.18981056]\n",
      "client auc [0.83690048 0.76633929 0.70924107 0.76223214 0.81071429 0.73390625\n",
      " 0.79174107 0.76285714 0.82196429 0.70464286]\n"
     ]
    }
   ],
   "source": [
    "split = [0.8, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T01:25:38.754808200Z",
     "start_time": "2023-08-28T01:21:57.417491600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split = [0.15, 0.15, 0.15, 0.15, 0.15,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "# run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split = [0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "# run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split = [0.08, 0.08, 0.08, 0.08, 0.08,\n",
    "#          0.08, 0.08, 0.08, 0.08, 0.08,\n",
    "#          0.02, 0.02, 0.02, 0.02, 0.02,\n",
    "#          0.02, 0.02, 0.02, 0.02, 0.02]\n",
    "# run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split = [0.08, 0.08, 0.08, 0.08, 0.08,\n",
    "#          0.08, 0.08, 0.08, 0.08, 0.08,\n",
    "#          0.02, 0.02, 0.02, 0.02, 0.02,\n",
    "#          0.02, 0.02, 0.02, 0.02, 0.02]\n",
    "# run_local(split) # epoch 15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split = [0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "#          0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "# run_local(split) # epoch 15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
