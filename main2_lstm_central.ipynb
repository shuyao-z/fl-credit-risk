{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import statistics\n",
    "import datetime\n",
    "from net_archs import LSTMModel2 as LSTMModel\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "nts = torch.load('./dataset2/nts.pt')\n",
    "y = torch.load('./dataset2/y.pt')\n",
    "ts1 = torch.load('./dataset2/ts1.pt')\n",
    "ts2 = torch.load('./dataset2/ts2.pt')\n",
    "ts3 = torch.load('./dataset2/ts3.pt')\n",
    "ts4 = torch.load('./dataset2/ts4.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def do_split(split, dataset):\n",
    "    nts_train, ts1_train, ts2_train, ts3_train, ts4_train, y_train = dataset\n",
    "    nts_eq = []\n",
    "    ts1_eq = []\n",
    "    ts2_eq = []\n",
    "    ts3_eq = []\n",
    "    ts4_eq = []\n",
    "    y_eq = []\n",
    "    # skf = StratifiedKFold(n_splits=10)\n",
    "    n_splits = 50\n",
    "    skf = KFold(n_splits=n_splits)\n",
    "    skf.get_n_splits(nts_train, y_train)\n",
    "    for i, (_, test_index) in enumerate(skf.split(nts_train, y_train)):\n",
    "        nts_eq.append(nts_train[test_index])\n",
    "        ts1_eq.append(ts1_train[test_index])\n",
    "        ts2_eq.append(ts2_train[test_index])\n",
    "        ts3_eq.append(ts3_train[test_index])\n",
    "        ts4_eq.append(ts4_train[test_index])\n",
    "        y_eq.append(y_train[test_index])\n",
    "\n",
    "    x_split = []\n",
    "    y_split = []\n",
    "\n",
    "    acc = 0\n",
    "    for s in split:\n",
    "        x_split.append((\n",
    "            torch.cat(nts_eq[acc:acc+int(s*n_splits)], 0),\n",
    "            torch.cat(ts1_eq[acc:acc+int(s*n_splits)], 0),\n",
    "            torch.cat(ts2_eq[acc:acc+int(s*n_splits)], 0),\n",
    "            torch.cat(ts3_eq[acc:acc+int(s*n_splits)], 0),\n",
    "            torch.cat(ts4_eq[acc:acc+int(s*n_splits)], 0)))\n",
    "        y_split.append(torch.cat(y_eq[acc:acc+int(s*n_splits)], 0))\n",
    "        acc += int(s*n_splits)\n",
    "\n",
    "    return x_split, y_split\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define train function\n",
    "from net_archs import LSTMModel2 as LSTMModel\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "def train_lstm(net, optimizer, x, y, X_test, y_test, num_epoch=4, batch_size=256):\n",
    "  print_every = -1\n",
    "\n",
    "  for n in range(num_epoch):\n",
    "    # Mini batch sgd\n",
    "    nts, ts1, ts2, ts3, ts4 = x\n",
    "    permutation = torch.randperm(nts.size()[0])\n",
    "    for i in range(0, nts.size()[0], batch_size):\n",
    "      indices = permutation[i:i+batch_size]\n",
    "      x_mini = (nts[indices], ts1[indices], ts2[indices], ts3[indices], ts4[indices])\n",
    "      y_mini = y[indices]\n",
    "      y_pred = net(x_mini)\n",
    "      loss = nn.MSELoss()(y_pred, y_mini)\n",
    "      optimizer.zero_grad()\n",
    "      loss.mean().backward()\n",
    "      optimizer.step()\n",
    "      if print_every != -1 and (i / batch_size) % print_every == 0:\n",
    "        print(f'Epoch: {n + 1}, Iteration: {round(i / batch_size)}, Loss: {loss.sum()}')\n",
    "    if print_every == -1:\n",
    "      print(f'Epoch: {n + 1}, Loss: {loss.sum()}')\n",
    "    test(net, X_test, y_test)\n",
    "\n",
    "def test(net, x_test, y_test):\n",
    "  with torch.no_grad():\n",
    "    y_pred = net(x_test)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_test = y_test.detach().numpy()\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'auc {auc} mse {mse}')\n",
    "    return mse, auc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_local(split, nts=nts, y=y, ts1=ts1, ts2=ts2, ts3=ts3, ts4=ts4):\n",
    "    mses = []\n",
    "    aucs = []\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(nts, y)):\n",
    "        print(f\"Fold {fold_idx + 1}:\")\n",
    "\n",
    "        nts_train, nts_test = nts[train_idx], nts[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        ts1_train = ts1[train_idx]\n",
    "        ts2_train = ts2[train_idx]\n",
    "        ts3_train = ts3[train_idx]\n",
    "        ts4_train = ts4[train_idx]\n",
    "        ts1_test = ts1[test_idx]\n",
    "        ts2_test = ts2[test_idx]\n",
    "        ts3_test = ts3[test_idx]\n",
    "        ts4_test = ts4[test_idx]\n",
    "\n",
    "        trainset = nts_train, ts1_train, ts2_train, ts3_train, ts4_train, y_train\n",
    "\n",
    "        x_split, y_split = do_split(split, trainset)\n",
    "\n",
    "        for X_train, y_train in zip(x_split, y_split):\n",
    "            start = datetime.datetime.now()\n",
    "\n",
    "            model = LSTMModel(layer_size=128, num_of_layers=2)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.00001)\n",
    "            train_lstm(model, optimizer, X_train, y_train, (nts_test, ts1_test, ts2_test, ts3_test, ts4_test), y_test, num_epoch=20, batch_size=256)\n",
    "            end = datetime.datetime.now()\n",
    "            time = end - start\n",
    "\n",
    "            mse, auc = test(model, (nts_test, ts1_test, ts2_test, ts3_test, ts4_test), y_test)\n",
    "\n",
    "            aucs.append(auc)\n",
    "            mses.append(mse)\n",
    "\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    time = end - start\n",
    "\n",
    "    print('splitting:', split)\n",
    "    print('mse:', mses)\n",
    "    print('auc: ', aucs)\n",
    "    print('Training time: ', time)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "run_local(split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split = [0.15, 0.15, 0.15, 0.15, 0.15, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "#run_local(split, nts, y, ts1, ts2, ts3, ts4)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
